---
title: From expectation maximization to stochastic variational inference
layout: post
hidden: True
comments: False
author: "Martin Krasser"
header-img: "img/distributed.png"
---

**Update, Dec. 17<sup>th</sup> 2019**: This article is superseded by the following two articles:

- [Latent variable models - part 1: Gaussian mixture models and the EM algorithm](/2019/11/21/latent-variable-models-part-1/)
- [Latent variable models - part 2: Stochastic variational inference and variational autoencoders](/2019/12/17/latent-variable-models-part-2/)

The variational autoencoder code of the superseded article is still used in [other](/2018/04/07/latent-space-optimization/) [articles](/2018/07/27/dfc-vae/) and kept [here](https://nbviewer.jupyter.org/github/krasserm/bayesian-machine-learning/blob/dev/autoencoder-applications/variational_autoencoder.ipynb?flush_cache=true) for further reference.
