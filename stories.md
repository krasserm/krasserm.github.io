---
layout: page
title: "Selected stories"
nav-entry: "Stories"
header-img: "img/distributed.png"
---

The following are selected stories about my work on [machine learning](#machine-learning), [agentic systems](#agentic-systems), [distributed systems](#distributed-systems), [event sourcing](#event-sourcing) and [system integration](#system-integration). They primarily cover [open source](/open-source/) work but also some closed source work in [industry projects](/industry/).

## Machine Learning

Since 2017, I develop AI search engines for digital asset management (DAM) system providers, supporting semantic, cross-modal search of images, videos, sounds and documents in asset databases. Assets can be retrieved with a combination of semantic search, keyword matching and metadata filtering. The search engines also support facial recognition for identity-constrained searches and image aesthetics assessment for selecting images with highest perceived quality. AI-based query analysis improves the semantic understanding of user queries, leading to better search result quality. AI models in the index and search pipelines are fine-tuned on both customer-specific and synthetic data for a better understanding of the customer's business domain. An initial version of the AI search engine was offered by [MerlinOne](https://merlinone.com/) as *Merlin Accelerated Intelligence (AI) Suite*. Its commercial success was a major factor in the [acquisition](https://www.canto.com/press-releases/canto-merlinone/) of MerlinOne by [Canto](https://www.canto.com/) in 2023.

I also implemented several research papers from scratch, either as an exercise or because I needed a custom implementation in a project. Examples include single image super-resolution models EDSR, WDSR and SRGAN in the [super-resolution](https://github.com/krasserm/super-resolution) repository ([citations](https://scholar.google.com/scholar?q=%22github.com%2Fkrasserm%2Fsuper-resolution%22+OR+%22krasserm.github.io%2F2019%2F09%2F04%2Fsuper-resolution%22)), selected components from several image captioning papers to implement an *image captioning transformer* in the [fairseq-image-captioning](https://github.com/krasserm/fairseq-image-captioning) repository ([citations](https://scholar.google.com/scholar?q=%22https%3A%2F%2Fgithub.com%2Fkrasserm%2Ffairseq-image-captioning%22)) and multimodal perception models Perceiver, Perceiver IO and Perceiver AR in the [perceiver-io](https://github.com/krasserm/perceiver-io) repository ([citations](https://scholar.google.com/scholar?q=%22https%3A%2F%2Fgithub.com%2Fkrasserm%2Fperceiver-io%22)). All repositories are meanwhile used and/or referenced in other research works (see citations). I especially enjoyed implementing [Perceiver AR](https://arxiv.org/abs/2202.07765), an auto-regressive sequence model with [cross-attention to long-range inputs](/2023/01/23/scaling-perceiver-ar/#perceiver-ar) and [rotary position embeddings](/2022/12/13/rotary-position-embedding/). It was a great oppurtunity to build and [train](https://github.com/krasserm/perceiver-io/blob/main/docs/training-examples.md#perceiver-ar) a GPT-like LLM from scratch.

My work on Bayesian statistics and Bayesian methods for machine learning is collected in the [bayesian-machine-learning](https://github.com/krasserm/bayesian-machine-learning) repository ([citations](https://scholar.google.com/scholar?q=%22krasserm%2Fbayesian-machine-learning%22+OR+%22krasserm.github.io%2F2018%2F03%2F21%2Fbayesian-optimization%22+OR+%22krasserm.github.io%2F2019%2F03%2F14%2Fbayesian-neural-networks%22+OR+%22krasserm.github.io%2F2020%2F11%2F04%2Fgaussian-processes%22)). Each notebook in this repository covers a single topic and combines an introduction, mathematical basics and a simple implementation. A simple connection from theory to running code is something that I missed in available literature when I started to learn about Bayesian approaches. This repository is an attempt to improve on that and also helped me to better understand each topic. It has been gratifying to receive encouraging feedback like in [Variational inference in Bayesian neural networks](/2019/03/14/bayesian-neural-networks/) or [Bayesian optimization](/2018/03/21/bayesian-optimization/), for example, or [in the repository directly](https://github.com/krasserm/bayesian-machine-learning/issues/2). This response suggests the repository may be helpful for others in their learning journey as well.

## Agentic systems

During my work on AI search engines, I started to explore LLM-based [agentic systems](https://www.deeplearning.ai/the-batch/welcoming-diverse-approaches-keeps-machine-learning-strong/), enabling search engines to handle more complex, multi-step queries. Although most applications use the power of commercial, API-based models, I was also interested in using smaller, open LLMs for deployment in resource-constrained environments. I experimented with [fine-tuning 7B LLMs on planning tasks](/2024/05/31/planner-fine-tuning/) with synthetic agent trajectories and was able to reach GPT-4 level planning performance. [Application examples](/2024/05/31/planner-fine-tuning/#real-environment) include agentic RAG with open source [search tools](https://github.com/krasserm/bot-with-plan/tree/master/gba/tools/search#search-tools), combined with usage of other tools for sending emails, updating calendars or executing generated code. Despite promising results, it is also important to understand the [limitations of LLMs in planning tasks](https://arxiv.org/abs/2402.01817) and options for using them in combination with external verifiers.

My current focus in open source is on [freeact](https://github.com/gradion-ai/freeact), a lightweight library for building code-action based agents. Unlike traditional agent approaches that constrain actions to predefined tool sets or structured formats like JSON, freeact enables agents to express actions directly in code, leveraging the full Python ecosystem. The library executes generated code actions within [ipybox](https://github.com/gradion-ai/ipybox), a secure execution environment built on IPython and Docker. Agents can learn from execution results and environmental feedback, storing successful code actions as reusable skills in long-term memory. This approach is supported by [recent](https://arxiv.org/abs/2402.01030) [research](https://arxiv.org/abs/2411.01747) showing that code-based actions can achieve up to 20% higher success rates compared to conventional methods. 

## Distributed systems

From 2014 to 2017, I mainly worked on the global distribution of an [international customer](https://www.redbullmediahouse.com/)'s in-house digital asset management platform. State replication across multiple datacenters, low-latency write access to replicated state and write-availability during inter-datacenter network partitions were important requirements from the very beginning. We decided to follow an event sourcing approach for persistence and developed an event replication mechanism that preserves the causal ordering of events in event streams. For replicated state, we used a causal consistency model which is the strongest form of consistency that is still compatible with AP of [CAP](https://de.wikipedia.org/wiki/CAP-Theorem). The implementation was based on both generic and domain-specific [operation-based CRDTs](/2016/10/19/operation-based-crdt-framework/). I was responsible for the complete distributed systems architecture and the development of the generic platform components. These components evolved into the [Eventuate](https://github.com/RBMHTechnology/eventuate) open source project of which I'm the founder and lead developer. Eventuate has several production deployments.

We also used Eventuate to build distributed systems composed of microservices that collaborate via events. With Eventuate, services can rely on consuming events from local event logs in correct causal order, without duplicates. They can also rely on the write-availability of local event logs during network partitions and the reliable delivery of written events to collaborators. Eventuate-based microservice systems are conceptually similar to those that can be built with [Apache Kafka](http://kafka.apache.org/) and [Kafka Streams](http://kafka.apache.org/10/documentation/streams/) but Eventuate additionally implements a causal consistency model for systems that are distributed across multiple datacenters.

I already worked with globally distributed systems in 2004 where I developed a distributed computing solution for an international pharmaceutical company. In their drug discovery pipeline they used several computing services, deployed at different locations around the globe, for analyzing chemical structures regarding their biological activity. The developed solution integrated these computing services and enabled researchers to run them with a single mouse click from a chemical spreadsheet. The solution managed the reliable execution of compute jobs, persisted the results and delivered them back to the user. It ran in production for many years and was an integral part of the drug discovery pipeline of that company.

## Event sourcing

I use [event sourcing](https://martinfowler.com/eaaDev/EventSourcing.html) since 2011 in my projects. I started to apply that approach during the development of an electronic health record for an international customer. Event sourcing proved to be the right choice in this project given the demanding read and write throughput requirements and the needed flexibility to integrate with other healthcare IT systems. I later generalized that work in the [Eventsourced](https://github.com/eligosource/eventsourced) open source project that I developed in collaboration with [Eligotech](http://www.eligotech.com/). Eventsourced adds persistence to stateful [Akka](https://akka.io/) actors by writing inbound messages to a journal and replaying them on actor restart. Eventsourced was used as persistence solution in Eligotech products.

In 2013, Eventsourced attracted the interest of [Lightbend](https://www.lightbend.com/) (formerly Typesafe) and we decided to start a collaboration to build [Akka Persistence](https://doc.akka.io/docs/akka/current/persistence.html) which is now the official successor of Eventsourced. I was responsible for the complete development of Akka Persistence, from initial idea to production quality code. Akka Persistence has numerous production deployments today and is used as persistence mechanism in the [Lagom microservices framework](https://www.lagomframework.com/). I also developed the [Cassandra storage plugin](https://github.com/akka/akka-persistence-cassandra) for Akka Persistence which is now the officially recommended plugin for using Akka Persistence in production.

In 2014, I started to further develop the idea of Akka Persistence in the [Eventuate](https://github.com/RBMHTechnology/eventuate) open source project. Among other features, Eventuate additionally supports the replication of persistent actors, up to [global scale](/2015/01/13/event-sourcing-at-global-scale/). The replication mechanism supports a causal consistency model which is the strongest form of consistency that is still compatible with AP of CAP. The concepts of Eventuate are closely related to those of operation-based CRDTs which is further described in [this blog post](/2016/10/19/operation-based-crdt-framework/) (see also section [Distributed Systems](#distributed-systems)).

## System integration

In 2006, I started to work on a project at [ICW](https://icw-global.com/) in which we integrated hospital information systems of several customers using IHE standards. Technical basis for the integration solutions was the [Apache Camel](http://camel.apache.org/) integration framework for which I developed integration components that implement actor interfaces of several [IHE](https://www.ihe.net/) profiles and a DSL for processing  [HL7](http://www.hl7.org/) messages and [CDA](http://hl7.de/themen/hl7-cda-clinical-document-architecture/) documents (see also [this article](https://dzone.com/articles/introduction-open-ehealth) for an introduction). In 2009, these extensions have been open sourced as [Open eHealth Integration Platform](http://oehf.github.io/ipf/) (IPF) of which I'm the founder and initial lead developer. IPF has many production deployments in international customer projects today and is still actively developed by ICW, the sponsor of the open source project. IPF is a central component of ICW's *eHealth Suite* and provides connectivity to a wide range of healthcare information systems. Its standard compliance has been certified in several [IHE Connectathons](https://www.ihe.net/connectathon.aspx). During my work on IPF I also became an Apache Camel committer.

To meet the increasing scalability requirements in some IPF projects I started to investigate alternatives to Apache Camel's routing engine. I decided to use [Akka](https://akka.io/) actors for message routing and processing which proved to be a better basis for scaling IPF applications under load. The result of these efforts was the [akka-camel](https://doc.akka.io/docs/akka/2.5.4/scala/camel.html) module that I contributed to Akka in 2011. It implements a generic integration layer between Akka actors and Apache Camel components, including the IHE components of IPF.

I also developed other routing engine alternatives that follow a pure functional programming approach. A first attempt was [scalaz-camel](https://github.com/krasserm/scalaz-camel) which is now superseded by the [Streamz](https://github.com/krasserm/streamz) project which I actively developed with other contributors over many years. It allows application developers to integrate Apache Camel components into [FS2](https://github.com/functional-streams-for-scala/fs2) applications with a high-level integration DSL. It also supports that DSL on top of [Akka Streams](https://doc.akka.io/docs/akka/current/stream/index.html). Streamz is meanwhile the official replacement for akka-camel and part of the [Alpakka](https://github.com/akka/alpakka) ecosystem.
